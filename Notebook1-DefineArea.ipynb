{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this first notebook, we demonstrate how to define the location of interest and relevant time period to extract relevant altimeter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset as NetCDFFile \n",
    "from netCDF4 import num2date, date2num, date2index\n",
    "import datetime as dt\n",
    "# from StringIO import StringIO\n",
    "# import xarray as xr\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Extract altimeter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download list of altimeter URLS from Australian Ocean Data Network (AODN) as a txt file, here named IMOSURLS.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractURLsatellite(fileURL, satName):\n",
    "    \"\"\"\n",
    "    Function to extract the URLs for a specific satellite from the IMOS URLs list\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    - fileURL : IMOS URLs list as a txt file\n",
    "    - satName : name of the satellite such as JASON-2 JASON-3 \n",
    "    \n",
    "    Ouputs:\n",
    "    ------\n",
    "    \n",
    "    - getFiles : list of URLs for the desired satellite\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    getFiles = []\n",
    "    \n",
    "    with open(fileURL) as f:\n",
    "        for line in f:\n",
    "            if re.search(r\"%s\"%satName, line):\n",
    "                changeURL = re.sub('http://data.aodn.org.au', 'http://thredds.aodn.org.au/thredds/dodsC', line)\n",
    "                getFiles.append(changeURL)\n",
    "                \n",
    "    return getFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jason2URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'JASON-2')\n",
    "\n",
    "jason3URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'JASON-3')\n",
    "\n",
    "saralURL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'SARAL')\n",
    "\n",
    "sentinel3aURL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'SENTINEL-3A')\n",
    "\n",
    "cryosat2URL = extractURLsatellite( fileURL = 'IMOSURLs.txt', satName = 'CRYOSAT-2')\n",
    "\n",
    "enviURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'ENVISAT')\n",
    "\n",
    "geosatURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'GEOSAT')\n",
    "\n",
    "ersURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'ERS-2')\n",
    "\n",
    "gfoURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'GFO')\n",
    "\n",
    "topURL = extractURLsatellite(fileURL = 'IMOSURLs.txt', satName = 'TOPEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allURL = []\n",
    "allURL.append(jason2URL)\n",
    "allURL.append(jason3URL)\n",
    "allURL.append(saralURL)\n",
    "allURL.append(sentinel3aURL)\n",
    "allURL.append(cryosat2URL)\n",
    "allURL.append(enviURL)\n",
    "allURL.append(geosatURL)\n",
    "allURL.append(ersURL)\n",
    "allURL.append(gfoURL)\n",
    "allURL.append(topURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Define area and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example latitude and longitude\n",
    "latmin = -27.0\n",
    "latmax = -10.0  \n",
    "lonmin = 143.0\n",
    "lonmax = 155.0 \n",
    "\n",
    "if latmin>latmax:\n",
    "    print('Error wrong definition of min and max lat')\n",
    "\n",
    "if lonmin>lonmax:\n",
    "    print('Error wrong definition of min and max lon')\n",
    "\n",
    "#Example time\n",
    "start_date = dt.datetime(1985,1,1) \n",
    "end_date = dt.datetime(2018,12,31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments\n",
    "\n",
    "- lat: latitude\n",
    "- lon: longitude\n",
    "- wh: significant wave height\n",
    "- t: time\n",
    "- qc: quality control flag, one represents \"very good data\" (Ribal and Young 2019)\n",
    "- back: backscatter\n",
    "- ws: windspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Define arguments based on time and spatial location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxLat = [] \n",
    "boxLon = [] \n",
    "boxWh = [] \n",
    "boxT = [] \n",
    "boxQ = [] \n",
    "boxB = [] \n",
    "boxWS = [] \n",
    "\n",
    "\n",
    "newday_it = 0\n",
    "\n",
    "for u in range(len(allURL)):\n",
    "    urlON = allURL[u]\n",
    "    for k in range(len(urlON)):\n",
    "        ncs = NetCDFFile(urlON[k])\n",
    "        lats = ncs.variables['LATITUDE'][:]\n",
    "        lons = ncs.variables['LONGITUDE'][:]\n",
    "        ws = ncs.variables['WSPD_CAL'][:]\n",
    "        \n",
    "        \n",
    "        if u == 2: #Saral altimeter\n",
    "            wh = ncs.variables['SWH_KA_CAL'][:]\n",
    "            qc = ncs.variables['SWH_KA_quality_control'][:]\n",
    "            back = ncs.variables['SIG0_KA'][:]\n",
    "        \n",
    "        else:\n",
    "            wh = ncs.variables['SWH_KU_CAL'][:]\n",
    "            qc = ncs.variables['SWH_KU_quality_control'][:]\n",
    "            back = ncs.variables['SIG0_KU'][:]\n",
    "             \n",
    "        # Get desired time interval  \n",
    "        time_var = ncs.variables['TIME']\n",
    "        tt = ncs.variables['TIME'][:]\n",
    "        timing = netCDF4.num2date(tt,time_var.units)\n",
    "\n",
    "        newday_it = 0\n",
    "        if lats.min() >= latmin and lats.min() <= latmax:\n",
    "            if lons.min() >= lonmin and lons.min() <= lonmax:\n",
    "                for p in range(len(timing)):\n",
    "                    if timing[p] >= start_date and timing[p] <= end_date:\n",
    "                        if wh[p]>0:\n",
    "                            if qc[p]==1:\n",
    "                                t1 = netCDF4.num2date(tt[p],u'days since 1985-01-01 00:00:00 UTC')\n",
    "\n",
    "                                if newday_it == 0:\n",
    "                                    dd = netCDF4.num2date(tt[p],u'days since 1985-01-01 00:00:00 UTC')\n",
    "                                    newday_it = p\n",
    "                                else:\n",
    "                                    if t1.day != dd.day:\n",
    "\n",
    "                                        dd = netCDF4.num2date(tt[p],u'days since 1985-01-01 00:00:00 UTC')\n",
    "                                        tmpwh = wh[newday_it:p]\n",
    "                                        tmpback = back[newday_it:p]\n",
    "                                        tmpws = ws[newday_it:p]\n",
    "                                        tmpqc = qc[newday_it:p]\n",
    "                                        tmplat = lats[newday_it:p]\n",
    "                                        tmplon = lons[newday_it:p]\n",
    "                                        tmptt = tt[newday_it:p]\n",
    "                                        \n",
    "                                        iddd = np.where(np.logical_and(tmpqc==1,tmpwh>=0))\n",
    "                                        boxWh.append(np.median(tmpwh[iddd]))\n",
    "                                        boxB.append(np.median(tmpback[iddd]))\n",
    "                                        boxWS.append(np.median(tmpws[iddd]))\n",
    "                                        boxQ.append(np.median(tmpqc[iddd]))\n",
    "                                        boxLat.append(np.median(tmplat[iddd]))\n",
    "                                        boxLon.append(np.median(tmplon[iddd]))\n",
    "                                        boxT.append((tmptt[0])) \n",
    "                                        newday_it = p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(boxLat)):\n",
    "    if k == 0:\n",
    "        lat = boxLat[k]\n",
    "        lon = boxLon[k]\n",
    "        wh = boxWh[k]\n",
    "        tt = boxT[k]\n",
    "        qc = boxQ[k]\n",
    "        back = boxB[k]\n",
    "        ws = boxWS[k]\n",
    "    else:\n",
    "        lat = np.append(lat,boxLat[k])\n",
    "        lon = np.append(lon,boxLon[k])\n",
    "        wh = np.append(wh,boxWh[k])\n",
    "        tt = np.append(tt,boxT[k])\n",
    "        qc = np.append(qc,boxQ[k])\n",
    "        back = np.append(back,boxB[k])\n",
    "        ws = np.append(ws,boxWS[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Create dataframe and file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {'lat':lat.flatten(),\n",
    "     'lon':lon.flatten(),\n",
    "     'wh':wh.flatten(),\n",
    "     'tt':tt.flatten(),\n",
    "     'qc':qc.flatten(),\n",
    "     'back':back.flatten(),\n",
    "     'ws':ws.flatten()\n",
    "    })\n",
    "nameCSV = 'filename.csv'\n",
    "df.to_csv(str(nameCSV),columns=['lat', 'lon', 'wh', 'tt', 'qc', 'back','ws'], sep=' ', index=False ,header=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
